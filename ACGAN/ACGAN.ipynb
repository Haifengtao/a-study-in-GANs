{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0SyZ7H7lVeD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from math import ceil,log2\n",
    "import random\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "# from model import generator, discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9zdR8KXnBxF"
   },
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "\n",
    "    def __init__(self, encoding_dims = 100, step_channels = 6\n",
    "                 , out_channels = 3):\n",
    "        super(G, self).__init__()\n",
    "        \n",
    "        nz = encoding_dims\n",
    "        ngf = step_channels\n",
    "        nc = out_channels\n",
    "        \n",
    "        self.conv1 = nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf * 8)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 4)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf * 2)\n",
    "\n",
    "        self.conv4 = nn.ConvTranspose2d(ngf * 2, ngf * 1, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf * 1)\n",
    "\n",
    "        self.conv5 = nn.ConvTranspose2d(ngf * 1, nc, 4, 2, 1)\n",
    "\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.__initialize_weights()\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input.view(input.size(0), -1, 1, 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        output = self.tanh(x)\n",
    "        return output\n",
    "    \n",
    "def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "# class generatora(nn.Module):\n",
    "  \n",
    "#   def __init__(\n",
    "#       self,\n",
    "#       encoding_dims = 100,\n",
    "#       out_size = 32,\n",
    "#       out_channels = 3,\n",
    "#       step_channels = 64,\n",
    "#       nonlinearity = None,\n",
    "#       last_nonlinearity = None\n",
    "#   ):\n",
    "#     super().__init__()\n",
    "    \n",
    "#     if out_size < 16 or ceil(log2(out_size)) != log2(out_size):\n",
    "#             raise Exception(\n",
    "#                 \"Target Image Size must be at least 16*16 and an exact power of 2\"\n",
    "#             )\n",
    "        \n",
    "#     num_repeats = out_size.bit_length() - 4\n",
    "#     d = (step_channels*(2**num_repeats))\n",
    "    \n",
    "#     self.encoding_dims = encoding_dims\n",
    "\n",
    "#     nl = nn.LeakyReLU(.2) if nonlinearity is None else nonlinearity\n",
    "#     last_nl = nn.Tanh() if last_nonlinearity is None else last_nonlinearity\n",
    "    \n",
    "#     model =[]\n",
    "    \n",
    "#     model.append(\n",
    "#         nn.Sequential(\n",
    "#           nn.ConvTranspose2d(encoding_dims, d, 4, 1, 0),\n",
    "#           nn.BatchNorm2d(d),\n",
    "#           nl\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     for i in range(num_repeats):\n",
    "#       model.append(\n",
    "#           nn.Sequential(\n",
    "#           nn.ConvTranspose2d(d, d//2, 4, 2, 1),\n",
    "#           nn.BatchNorm2d(d//2),\n",
    "#           nl\n",
    "#           )\n",
    "#       )\n",
    "      \n",
    "#       d = d//2\n",
    "    \n",
    "    \n",
    "#     model.append(\n",
    "#         nn.Sequential(\n",
    "#             nn.ConvTranspose2d(step_channels, out_channels, 4, 2, 1, bias = True),\n",
    "#             last_nl\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     self.model = nn.Sequential(*model)\n",
    "#     self._weight_initializer()\n",
    "    \n",
    "#   def forward(self,x):\n",
    "    \n",
    "#     x = x.view(-1, self.encoding_dims, 1, 1)\n",
    "#     return self.model(x)\n",
    "  \n",
    "  \n",
    "#   def _weight_initializer(self):\n",
    "#         r\"\"\"Default weight initializer for all generator models.\n",
    "#         Models that require custom weight initialization can override this method\n",
    "#         \"\"\"\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.ConvTranspose2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight)\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1.0)\n",
    "#                 nn.init.constant_(m.bias, 0.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1M1xjranE7h"
   },
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, ndf, nc, num_classes=10):\n",
    "        super(D, self).__init__()\n",
    "        \n",
    "        ndf = step_channels\n",
    "        nc = in_channels\n",
    "        \n",
    "        \n",
    "        self.ndf = ndf\n",
    "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv1 = nn.Conv2d(nc, ndf, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv5 = nn.Conv2d(ndf * 8, ndf * 1, 4, 1, 0)\n",
    "        self.gan_linear = nn.Linear(ndf * 1, 1)\n",
    "        self.aux_linear = nn.Linear(ndf * 1, num_classes)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.__initialize_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.conv1(input)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.lrelu(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(-1, self.ndf * 1)\n",
    "        c = self.aux_linear(x)\n",
    "\n",
    "        s = self.gan_linear(x)\n",
    "        s = self.sigmoid(s)\n",
    "        return s.squeeze(1), c.squeeze(1)\n",
    "\n",
    "    def __initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.normal_(1.0, 0.02)\n",
    "                m.bias.data.fill_(0)\n",
    "                \n",
    "\n",
    "# class discriminatora(nn.Module):\n",
    "  \n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         num_classes,\n",
    "#         in_size = 32,\n",
    "#         in_channels = 3,\n",
    "#         step_channels = 64,\n",
    "#         nonlinearity = None,\n",
    "#         last_nonlinearity = None\n",
    "#     ):\n",
    "    \n",
    "#         super().__init__()\n",
    "    \n",
    "#         if in_size < 16 or ceil(log2(in_size)) != log2(in_size):\n",
    "#             raise Exception(\n",
    "#                 \"Input Image Size must be at least 16*16 and an exact power of 2\"\n",
    "#             )\n",
    "    \n",
    "#         self.num_classes = num_classes\n",
    "#         num_repeats = in_size.bit_length() - 4\n",
    "#         d = step_channels \n",
    "#         model = []\n",
    "\n",
    "#         nl = nn.LeakyReLU(.2) if nonlinearity is None else nonlinearity\n",
    "#         last_nl = nn.LeakyReLU(.2) if last_nonlinearity is None else last_nonlinearity\n",
    "\n",
    "#          model.append(\n",
    "#             nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels, d, 4, 2, 1, bias = True),\n",
    "#                 nl)\n",
    "#         )\n",
    "\n",
    "#         for i in range(num_repeats):\n",
    "\n",
    "#             model.append(\n",
    "#                 nn.Sequential(\n",
    "#                     nn.Conv2d(d, d*2, 4, 2, 1, bias = False),\n",
    "#                      nn.BatchNorm2d(d*2),\n",
    "#                      nl\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#              d = d*2\n",
    "\n",
    "\n",
    "#         self.disc = nn.Sequential(\n",
    "#                 nn.Conv2d(d, 1, 4, 1, 0, bias = True),\n",
    "#                 nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#         self.aux = nn.Sequential(\n",
    "#                 nn.Conv2d(d, self.num_classes, 4, 1, 0, bias = True),\n",
    "#                 last_nl\n",
    "#         )\n",
    "\n",
    "      \n",
    "#         self.model = nn.Sequential(*model)\n",
    "#         self._weight_initializer()\n",
    "          \n",
    "  \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         x = self.model(x)\n",
    "#         dx = self.disc(x)\n",
    "#         ax = self.aux(x)\n",
    "        \n",
    "#         return dx.view(-1), ax.view(-1, self.num_classes) \n",
    "        \n",
    "#     def _weight_initializer(self):\n",
    "#         r\"\"\"Default weight initializer for all disciminator models.\n",
    "#         Models that require custom weight initialization can override this method\n",
    "#         \"\"\"\n",
    "#         for m in self.modules():\n",
    "#             if isinstance(m, nn.Conv2d):\n",
    "#                 nn.init.kaiming_normal_(m.weight)\n",
    "#             elif isinstance(m, nn.BatchNorm2d):\n",
    "#                 nn.init.constant_(m.weight, 1.0)\n",
    "#                 nn.init.constant_(m.bias, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YgN6RwLcpCcc",
    "outputId": "7205bfa8-a094-4283-8ef7-f374fd138e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLgO-m-fpy--"
   },
   "outputs": [],
   "source": [
    "class parser():\n",
    "  def __init__(self):\n",
    "    self.num_classes = 10\n",
    "    self.encoding_dims = 100\n",
    "    self.batch_size = 64\n",
    "    self.epochs = 4\n",
    "    self.image_size = 64\n",
    "    self.num_workers = 4\n",
    "    self.channels = 1\n",
    "    self.step_channels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imXyDbsrqB9c"
   },
   "outputs": [],
   "source": [
    "parser = parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xYIOvFjHm1jM"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'encoding_dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-0733d84ad80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nirmal/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'encoding_dims'"
     ]
    }
   ],
   "source": [
    "generator = generator(encoding_dims = parser.encoding_dims, out_size = parser.image_size, out_channels = parser.channels, step_channels = parser.step_channels).to(device)\n",
    "discriminator = discriminator(num_classes = parser.num_classes, in_size = parser.image_size, in_channels = parser.channels, step_channels = parser.step_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqbkHH91ohnh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize(parser.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "dataset = torchvision.datasets.MNIST(root='./data', download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=parser.batch_size, shuffle=True, num_workers=parser.num_workers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2sbRC1qoq3x"
   },
   "outputs": [],
   "source": [
    "BCEloss = nn.BCELoss().to(device)\n",
    "CEPloss = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRbBD0NZpAyN"
   },
   "outputs": [],
   "source": [
    "optimG = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimD = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbrJ8t6QmH63"
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(parser.num_classes,parser.encoding_dims).to(device)\n",
    "fixed_labels = torch.LongTensor([range(parser.num_classes)]*10).view(-1).to(device)\n",
    "fixed_noise_init = torch.Tensor(100, parser.encoding_dims).normal_(0,1).to(device)\n",
    "fixed_noise = torch.mul(fixed_noise_init, embedding(fixed_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GenQzQaVpudm",
    "outputId": "61e206a1-035b-445b-a0c0-935cc5d83351"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got -nan at /pytorch/aten/src/THNN/generic/BCECriterion.c:62",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-da6c44f2c686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mreal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mCEPloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mfake_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_prediciton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mCEPloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mD_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfake_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nirmal/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nirmal/.local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nirmal/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2113\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Assertion `x >= 0. && x <= 1.' failed. input value should be between 0~1, but got -nan at /pytorch/aten/src/THNN/generic/BCECriterion.c:62"
     ]
    }
   ],
   "source": [
    "for epoch in range(parser.epochs):\n",
    "  \n",
    "  for i, data in enumerate(dataloader):\n",
    "    \n",
    "    print('done')\n",
    "    data_input, label = data\n",
    "    \n",
    "    #######################\n",
    "    # real input and label\n",
    "    #######################\n",
    "   \n",
    "    real_input = data_input.to(device)\n",
    "    real_label = label.to(device)\n",
    "    real_ = torch.ones((parser.batch_size)).to(device)\n",
    "    \n",
    "    #######################\n",
    "    # fake input and label\n",
    "    #######################\n",
    "    \n",
    "    noise_init = torch.Tensor(parser.batch_size, parser.encoding_dims).to(device)\n",
    "    fake_labels = torch.torch.LongTensor(parser.batch_size).random_(parser.num_classes).to(device)\n",
    "    noise = torch.mul(noise_init, embedding(fake_labels)).view(parser.batch_size, parser.encoding_dims, 1, 1).to(device)\n",
    "    fake_input = generator(noise)\n",
    "    fake_ = torch.zeros((parser.batch_size)).to(device)\n",
    "    \n",
    "    #######################\n",
    "    # update discriminator\n",
    "    #######################\n",
    "    \n",
    "    discriminator.zero_grad()\n",
    "    \n",
    "    real_prediction, real_class = discriminator(real_input)\n",
    "    fake_prediction, fake_class = discriminator(fake_input)\n",
    "    \n",
    "    real_loss = BCEloss(real_prediction, real_) + CEPloss(real_class, real_label)*10\n",
    "    fake_loss = BCEloss(fake_prediciton, fake_) + CEPloss(fake_class, fake_labels)*10\n",
    "    \n",
    "    D_loss = real_loss + fake_loss\n",
    "    D_loss.backward()\n",
    "    \n",
    "    optimD.step()\n",
    "    \n",
    "    #######################\n",
    "    # update generator\n",
    "    #######################\n",
    "    \n",
    "    generator.zero_grad()\n",
    "    \n",
    "    fake_predicition, fake_class = discriminator(fake_input)\n",
    "    \n",
    "    loss = BCEloss(fake_prediction, real_) + CEPloss(fake_class, fake_labels)*10\n",
    "    loss.backward()\n",
    "    optimG.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
