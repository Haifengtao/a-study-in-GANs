{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_crop_size(crop_size, upscale_factor):\n",
    "    return crop_size - (crop_size % upscale_factor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_HR_transform(crop_size):\n",
    "    return T.Compose([ T.RandomCrop(crop_size), T.ToTensor() ])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LR_transform(crop_size, upscale_factor):\n",
    "    transform = T.Compose([\n",
    "        T.ToPILImage(),\n",
    "        T.Resize(crop_size // upscale_factor, interpolation = Image.BICUBIC),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_train_from_folder(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset_dir, crop_size, upscale_factor):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_filename = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "        self.crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n",
    "        self.HR_transform = train_HR_transform(crop_size) \n",
    "        self.LR_transform = train_LR_transform(crop_size, upscale_factor)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        HR_image = self.HR_transform(Image.open(self.image_filename[idx]))\n",
    "        LR_image = self.LR_transform(HR_image)\n",
    "        \n",
    "        return HR_image, LR_image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ValDatasetFromFolder(Dataset):\n",
    "#     def __init__(self, dataset_dir, upscale_factor):\n",
    "#         super(ValDatasetFromFolder, self).__init__()\n",
    "#         self.upscale_factor = upscale_factor\n",
    "#         self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         hr_image = Image.open(self.image_filenames[index])\n",
    "#         w, h = hr_image.size\n",
    "#         crop_size = calculate_valid_crop_size(min(w, h), self.upscale_factor)\n",
    "#         lr_scale = Resize(crop_size // self.upscale_factor, interpolation=Image.BICUBIC)\n",
    "#         hr_scale = Resize(crop_size, interpolation=Image.BICUBIC)\n",
    "#         hr_image = CenterCrop(crop_size)(hr_image)\n",
    "#         lr_image = lr_scale(hr_image)\n",
    "#         hr_restore_img = hr_scale(lr_image)\n",
    "#         return ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.image_filenames)\n",
    "\n",
    "\n",
    "# class TestDatasetFromFolder(Dataset):\n",
    "#     def __init__(self, dataset_dir, upscale_factor):\n",
    "#         super(TestDatasetFromFolder, self).__init__()\n",
    "#         self.lr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/data/'\n",
    "#         self.hr_path = dataset_dir + '/SRF_' + str(upscale_factor) + '/target/'\n",
    "#         self.upscale_factor = upscale_factor\n",
    "#         self.lr_filenames = [join(self.lr_path, x) for x in listdir(self.lr_path) if is_image_file(x)]\n",
    "#         self.hr_filenames = [join(self.hr_path, x) for x in listdir(self.hr_path) if is_image_file(x)]\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         image_name = self.lr_filenames[index].split('/')[-1]\n",
    "#         lr_image = Image.open(self.lr_filenames[index])\n",
    "#         w, h = lr_image.size\n",
    "#         hr_image = Image.open(self.hr_filenames[index])\n",
    "#         hr_scale = Resize((self.upscale_factor * h, self.upscale_factor * w), interpolation=Image.BICUBIC)\n",
    "#         hr_restore_img = hr_scale(lr_image)\n",
    "#         return image_name, ToTensor()(lr_image), ToTensor()(hr_restore_img), ToTensor()(hr_image)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.lr_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
